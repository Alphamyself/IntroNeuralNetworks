{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter  2: Optimizing a Network with Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 1: Adjusting Weights Manually to Get a Better Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adjust the weights until you find the perfect output for is set of inputs\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# now use the from MSE to calculate errors for a series of sets of inputs, each set conaining the data to make a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2: Algorithm to Automatically Adjust Weights (Gradient Decent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Decent for a Single Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n49gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119606828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (From the slides on adjusting one node in a zero hidden layer network)\n",
    "# Play around with input, starting weight and predicted to see how the computer is adjusting the weight\n",
    "input = 4\n",
    "w = 100\n",
    "predicted = input * w\n",
    "expected = 5\n",
    "output = [predicted]\n",
    "for _ in range (39):\n",
    "    w -= 2 * (predicted - expected) * input * .01\n",
    "    predicted = input * w\n",
    "    output.append(predicted)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(range(40), output)\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Predicted')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gradient for Multiple Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the weights, input_data and target\n",
    "weights = np.array([5, 7])\n",
    "sleep = 8\n",
    "study = 5\n",
    "input_data = np.array([sleep, study])\n",
    "target = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessed 75 but actual value was 80. Calculated a gradient for the weights as [-80 -50] respectively.\n",
      "Recall that to update the weights, its weight = weight - gradient * learning_rate.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the prediction: prediction\n",
    "prediction = (weights * input_data).sum()\n",
    "\n",
    "# Calculate the error: error\n",
    "error = prediction - target\n",
    "\n",
    "# Calculate the gradient: gradient\n",
    "# Notice derivative of activation function \"missing\"... because no activation function on input nodes\n",
    "gradient = 2 * input_data * error\n",
    "\n",
    "# Print the gradient\n",
    "print(\"Guessed {} but actual value was {}. Calculated a gradient for the weights as {} respectively.\".format(prediction, target, gradient))\n",
    "print(\"Recall that to update the weights, its weight = weight - gradient * learning_rate.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Gradient Decent on Multiple Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5\n",
      "3.9\n"
     ]
    }
   ],
   "source": [
    "# Set the learning rate constant: LEARNING_RATE\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "# Calculate the prediction: prediction\n",
    "prediction = (weights * input_data).sum()\n",
    "\n",
    "# Calculate the error: error\n",
    "error = prediction - target\n",
    "\n",
    "# Calculate the gradient: gradient\n",
    "gradient = 2 * input_data * error\n",
    "\n",
    "# Update the weights: weights_updated\n",
    "weights_updated = weights -  gradient * LEARNING_RATE\n",
    "\n",
    "# Get updated prediction: pred_updated\n",
    "pred_updated = (weights_updated * input_data).sum()\n",
    "\n",
    "# Calculate updated error: error_updated\n",
    "error_updated = pred_updated - target\n",
    "\n",
    "# Print the original error\n",
    "print(error)\n",
    "\n",
    "# Print the updated error\n",
    "print(error_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Gradient Decent on Multiple Layers: Backpragation\n",
    "write it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 3: Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets\n",
      " [[ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 0.  1.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 0.  1.]\n",
      " [ 1.  0.]]\n",
      "Targets and predictors from titantic data set loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "%run data_wrangling_titantic.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Your First Classifier Model Using Keras!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add a hidden layer\n",
    "model.add(Dense(n_cols, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add another hidden layer\n",
    "model.add(Dense(n_cols, activation='sigmoid', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: categorical_crossentropy\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s - loss: 0.6081 - acc: 0.6857     \n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s - loss: 0.6015 - acc: 0.7015     \n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s - loss: 0.5965 - acc: 0.6992     \n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s - loss: 0.5904 - acc: 0.7104     \n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s - loss: 0.5843 - acc: 0.7093     \n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s - loss: 0.5792 - acc: 0.7116     \n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s - loss: 0.5734 - acc: 0.7093     \n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s - loss: 0.5692 - acc: 0.7149     \n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s - loss: 0.5633 - acc: 0.7183     \n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s - loss: 0.5564 - acc: 0.7194     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119d6c908>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(predictors, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_67_input to have shape (None, 12) but got array with shape (1, 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-394-edeb358b5d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Calculate predictions: predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Calculate predicted probability of survival: predicted_prob_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1552\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1553\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    131\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_67_input to have shape (None, 12) but got array with shape (1, 7)"
     ]
    }
   ],
   "source": [
    "# raw_data.columns\n",
    "# Predicting with the Model\n",
    "# Make a fake person (out-of-data sample)\n",
    "new_data = {'Pclass' : [3], 'Sex' : [0], 'Age' : [5], 'SibSp' : [4], 'Parch' : [2], 'Fare' : [0],\n",
    "       'Embarked' : [3]}\n",
    "df = pd.DataFrame(data=new_data)\n",
    "pred_data = df.as_matrix()\n",
    "\n",
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(pred_data)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
